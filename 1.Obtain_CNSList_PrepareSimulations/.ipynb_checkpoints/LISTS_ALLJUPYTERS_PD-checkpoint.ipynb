{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaca9aac",
   "metadata": {},
   "source": [
    "# Workflow for obtaining the final CNS protein list applying some filters \n",
    "\n",
    "##### IRB Barcelona\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b7c29",
   "metadata": {},
   "source": [
    "The aim of this workflow is to obtain a list of CNS proteins which meet certain requirements such as being membrane proteins, targetable, with a PDB structure and being included in the MemProtMD repository. \n",
    "\n",
    "The simulations of these proteins will be run in future steps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dcf11a",
   "metadata": {},
   "source": [
    "### ______\n",
    "\n",
    "### Table of contents for obtaining the worklflow\n",
    "\n",
    "1. List CNS\n",
    "\n",
    "\n",
    "    1.1. Bgee List\n",
    "    1.2. Human Protein Atlas List\n",
    "    1.3. Tissues List\n",
    "    1.4. Overlap List\n",
    "    \n",
    "\n",
    "\n",
    "2. Filters\n",
    "\n",
    "    a. Filter of biological interest\n",
    "\n",
    "        2.1. Drug Targetable (Opentarget and Pharos) --> Targets for PD \n",
    "        2.2. Membrane protein (Uniprot)\n",
    "      \n",
    "     b. Filter of structure\n",
    "        2.3. Length sequence > 100 aa (Uniprot)\n",
    "        2.4. PDB structure (PDB)\n",
    "       \n",
    "     c. Filter for simulations and inserted in membrane\n",
    "        2.5. In MemProtMD (MemProtMD)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "3. Choose those PDBs that are not equal\n",
    "\n",
    "### ______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2917427",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9afaf3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import urllib.request\n",
    "import json\n",
    "from typing import Generator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import json\n",
    "import urllib.request\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a47c17",
   "metadata": {},
   "source": [
    "### 1. Selection of proteins belonging to the Central Nervous System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70985c64",
   "metadata": {},
   "source": [
    "#### 1.1. Bgee List "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f268010",
   "metadata": {},
   "source": [
    "##### - Step 1. Visualize data and uniform it\n",
    "We are going to visualize some of the list of the proteins in order to see that it was downloaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where the file of all proteins is.\n",
    "\n",
    "path = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.1.Bgee database/Homo_sapiens_expr_simple.tsv'\n",
    "\n",
    "# Read the tsv. Tsv are limited by a t that's why it is called tsv.\n",
    "\n",
    "database_bgee = pd.read_csv(path,delimiter='\\t')\n",
    "\n",
    "database_bgee.head() # Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of entries of Bgee DB: ', len(database_bgee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the unique values in the Anatomical entity name column: \n",
    "\n",
    "unique_anato_id_bgee_notone = database_bgee['Anatomical entity ID'].unique().tolist()\n",
    "print(unique_anato_id_bgee_notone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71acb627",
   "metadata": {},
   "source": [
    "From visualizing we have taken into account that the column Anatomical entity ID can contain more than one ID. We are going to filter this. We are going to stay with the first one and then add the second one when the list is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473238ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_ids = [] # We store here the second ID\n",
    "\n",
    "for id_ in unique_anato_id_bgee_notone: # For each value of the column Anatomical entity ID\n",
    "    \n",
    "    if '∩' in id_: # If the intersection symbol is found:\n",
    "        splitted = id_.split() # The ID is splitted.\n",
    "        CL_ids.append(splitted[2]) # The third value which starts by CL is stored in a list. \n",
    "        database_bgee.replace(to_replace=id_, value=splitted[0], inplace = True, regex=True) # Then, the value of the column where the ID is double is subsituted for its first term\n",
    "        database_bgee[database_bgee['Anatomical entity ID'] == splitted[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_anato_id_bgee = database_bgee['Anatomical entity ID'].unique().tolist()  # Creation of unique list.\n",
    "\n",
    "unique_anato_id_bgee = unique_anato_id_bgee+CL_ids # Addition of the second ID to the list.\n",
    "\n",
    "genes = database_bgee['Gene name'].unique().tolist() # Creation of the unique list again just in case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf0414",
   "metadata": {},
   "source": [
    "##### - Step 2. Find which Anatomical entity ID are from CNS. \n",
    "\n",
    "We do a filter of this file to see which proteins are from the Central Nervous System. \n",
    "\n",
    "First we go to https://www.ebi.ac.uk/ols/search?q=Central+Nervous+System&groupField=iri&start=0&ontology=uberon where the anatomical region we specified as Central Nervous System. We choose the first one \" Central Nervous System\" as it is what we want to filter. \n",
    "\n",
    "We see that the ID of the CNS is UBERON:0001017. As the list of proteins we have uses this types of ID in the column Anatomical entity ID; we want to filter this column and obtain only those genes that have this ID.\n",
    "\n",
    "Moreover, theare are some genes that are classified as brain or other CNS parts and not as CNS. So we are also interested in collecting those. We want the Anatomical entity ID of CNS and other parts of CNS. To know these parts of CNS, in the uberon ontology of CNS there is a tree with the children of CNS. \n",
    "\n",
    "**What are we going to do**\n",
    "\n",
    "Note:\n",
    "We use better the ID rathen than the Anatomical entity name cause the ID is unique and the Anatomical entity name could be free text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Given a uberon code retunr a list with all its children uberon codes\n",
    "def ols_get_code_children (uberon_code : str) -> List[str]:\n",
    "    \n",
    "    child_codes = []\n",
    "    for page in range(0,3):# There are different pages because in one it does not fit all the data. In this case\n",
    "                            # there are 3 pages containing data. So in the url we have to iterate for eaach page\n",
    "                            # and from each one we extract the data. \n",
    "        # OLS url\n",
    "    \n",
    "        request_url = 'https://www.ebi.ac.uk/ols/api/ontologies/uberon/terms/http%253A%252F%252Fpurl.obolibrary.org%252Fobo%252F'+uberon_code+'/hierarchicalDescendants?size=1000&page='+str(page)\n",
    "        \n",
    "        try:\n",
    "            with urllib.request.urlopen(request_url) as response:\n",
    "                parsed_response = json.loads(response.read().decode(\"utf-8\"))\n",
    "        # If the accession is not found then we can stop here\n",
    "        except urllib.error.HTTPError as error:\n",
    "            print('Error with request ' + request_url)\n",
    "            raise ValueError('Something went wrong with the PDB request (error ' + str(error.code) + ')')\n",
    "        # Mine children codes\n",
    "        embedded = parsed_response.get('_embedded', None)\n",
    "        if not embedded:\n",
    "            return []\n",
    "        children = embedded['terms']\n",
    "\n",
    "        for child in children:\n",
    "            #print(child['label'])\n",
    "            child_code = child['iri'].split('/')[-1] #We select the last element of the iri because it is where the \n",
    "                                                    # UBERON code is.\n",
    "            child_codes.append(child_code) # We append it to the list of children.\n",
    "            \n",
    "        # Return childrn codes\n",
    "    return child_codes\n",
    "\n",
    "all_descendents = ols_get_code_children('UBERON_0001017')\n",
    "\n",
    "    \n",
    "print(len(all_descendents))\n",
    "print(all_descendents[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the following loop in the next cell (to search the web), the codes of the UBERON have to be with _ not :\n",
    "# We change : for _\n",
    "\n",
    "all_descendents_colon= [] #New list of values with _ not :\n",
    "\n",
    "for i in range(0,len(all_descendents)): \n",
    "    all_descendents_colon.append(all_descendents[i].replace(\"_\", \":\" )) #We replace : for _ and we insert it to the list. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c096512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select those codes from the table that are children of CNS (all descendents_colon)\n",
    "\n",
    "PartsCNS_TF = database_bgee['Anatomical entity ID'].isin(all_descendents_colon)\n",
    "\n",
    "PartsCNS=database_bgee[PartsCNS_TF]\n",
    "PartsCNS.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a061f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now select all the codes from the table that corresponds to the CNS: \n",
    "\n",
    "CNS = database_bgee[database_bgee['Anatomical entity ID']=='UBERON:0001017']\n",
    "\n",
    "# We join the two tables obtained: the one for the CNS parts (children of CNS) and the one from CNS.\n",
    "CNS_and_PartsCNS = pd.concat([CNS,PartsCNS])\n",
    "\n",
    "CNS_and_PartsCNS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of entries when selecting CNS proteins and its parts: ',len(CNS_and_PartsCNS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88208af4",
   "metadata": {},
   "source": [
    "##### - Step 3. Do a filter for Expression = present\n",
    "We want only those genes that are expressed in order to have a protein list not a gene list.\n",
    "We want to do it before the duplicates removal because if it is done after, the duplicates removal function drop_duplicates can select one gene that it is not expressed in some anatomical entity and in other one yes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select those which are expressed. \n",
    "\n",
    "expressed = CNS_and_PartsCNS[CNS_and_PartsCNS['Expression'] == 'present']\n",
    "\n",
    "expressed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compare how much genes we have discarted, how much are not expressed. \n",
    "\n",
    "print('Number of entries when selecting CNS proteins and its parts: ',len(CNS_and_PartsCNS))\n",
    "print('Number of entries when selecting CNS proteins and its parts with protein expression: ',len(expressed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b058929",
   "metadata": {},
   "source": [
    "##### - Step 4. Filter those repeated\n",
    "\n",
    "We have obtained a list which includes proteins from the Central Nervous System and all its components. However, maybe there are some repeated. We have to remove the duplications in order to have unique values. \n",
    "\n",
    "We do not put any condition (prioritazing CNS e.g.) because we are only interested in those genes expressed, not other variables such as how much are expressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe400c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We filter those genes that may be repeated in the table.\n",
    "\n",
    "noduplicates= expressed.drop_duplicates(subset=['Gene ID'])\n",
    "noduplicates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compare how much genes we have discarted:\n",
    "\n",
    "print('Number of entries when selecting CNS proteins and its parts with protein expression: ',len(expressed))\n",
    "print('Number of entries when selecting CNS proteins and its parts with protein expression and without duplicates genes: ', len(noduplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b12f7",
   "metadata": {},
   "source": [
    "##### - Step 5. Uniprot overlap\n",
    "\n",
    "When doing this overlap with uniprot we are making sure that: \n",
    "\n",
    "    1. Genes codify for proteins\n",
    "    2. Genes are reviewed by Uniprot \n",
    "    \n",
    " \n",
    "We choose the Gene ID and save them in the folder in the in order to introduce them in the Mapping of Uniprot with the objective to go from a ENSG id (Ensembl) to a Uniprot ID.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0bf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_ENG_ID = noduplicates['Gene ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ac789",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_ENG_ID.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.1.Bgee database/ID_Bgee_MapBy_ENSG_output.txt', header=None, index=None, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d649f",
   "metadata": {},
   "source": [
    "This list has to be loaded to UniProt Mapping tool, found in the following url: https://www.uniprot.org/id-mapping, with parameters: \n",
    "- From database: Ensembl\n",
    "- To database: UniProtKB\n",
    "\n",
    "Once obtained the mapping result, one should downloaded the resulting table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7b3de",
   "metadata": {},
   "source": [
    "##### - Step 6. Correct list obtained from mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f045ae4c",
   "metadata": {},
   "source": [
    "The resulting table from the UniProt mapping tool is loaded in the workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Bgee = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.1.Bgee database/Uniprot_Mapped_Bgee_2023.02.02-12.32.04.35_input.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ebdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bgee_CNS = pd.read_csv(path_Bgee,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff3842",
   "metadata": {},
   "source": [
    "We select only those UniProt IDs that are reviewed and remove possible duplicates from the 'Entry' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba353747",
   "metadata": {},
   "outputs": [],
   "source": [
    "BgeeCNS_List_Reviewed = Bgee_CNS[Bgee_CNS['Reviewed']=='reviewed'] # We choose those which are reviewed\n",
    "\n",
    "Bgee_corrected = BgeeCNS_List_Reviewed.drop_duplicates(subset=['Entry']) # There are duplicates from Bgee so we remove them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab44fbc",
   "metadata": {},
   "source": [
    "##### -  7. Save the CNS list from Bgee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bgee_corrected.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.1.Bgee database/1.Bgee_ready_output.csv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8254e",
   "metadata": {},
   "source": [
    "# __________________________\n",
    "\n",
    "#### 1.2. Human Protein Atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310dcbe",
   "metadata": {},
   "source": [
    "##### - Step 1. Downloading of HPA database\n",
    "We have downloaded from Human Protein Atlas the proteins which should be in the human brain. \n",
    "\n",
    "Out of the 16465 genes detected above cut off in the human brain, 2685 genes have an elevated expression in the brain compared to other tissue types. So we have selected the list from the 16465 genes because although they are not hihgly expressed, they can have an important function.\n",
    "\n",
    "Moreover, this database from the Human Protein Atlas is also considered from the Central Nervous System as it involves:\n",
    "\n",
    "- Amygdala\n",
    "- Basal ganglia\n",
    "- Hippocampal formation\n",
    "- Cerebral cortex\n",
    "- Cerebellum\n",
    "- Spinal cord\n",
    "- Medulla obliongata\n",
    "- Pons\n",
    "- Midbrain\n",
    "- Thalamus\n",
    "- Hypothalamus\n",
    "- White matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68859b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the list\n",
    "\n",
    "database_hpa = pd.read_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.2.HPA database/NOT.tsv',delimiter='\\t')\n",
    "\n",
    "database_hpa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of entries in the Human Protein Atlas DB', len(database_hpa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175082de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Values of unique values in Evidence column ', pd.unique(database_hpa['Evidence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1f23f",
   "metadata": {},
   "source": [
    "##### - Step 2. Filter for Evidence at protein level\n",
    "\n",
    "We are going to filter and stay with those that the Evidence column is 'present at protein level' in order to only have those genes that code for proteins and not those that code for non-coding RNA.\n",
    "\n",
    "We do this filter in order to be more accurate with the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_hpa_protein = database_hpa[database_hpa['Evidence'] =='Evidence at protein level']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb772e74",
   "metadata": {},
   "source": [
    "We see that some cells of the column 'Uniprot' are empty. This is because there is no Uniprot code for that gene. \n",
    "It was seen that 100 in the above table do not have a UniProt code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3cfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique UniProt IDs: ', len(pd.unique(database_hpa_protein['Uniprot'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6320b25a",
   "metadata": {},
   "source": [
    "##### - Step 3. Correct list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d307e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa_corrected = database_hpa_protein.drop_duplicates(subset=['Uniprot']) # There are duplicates from HPA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6bca08",
   "metadata": {},
   "source": [
    "##### - 4. Save the CNS list from HPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa_corrected.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.2.HPA database/2.HPA_ready_output.csv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe146087",
   "metadata": {},
   "source": [
    "# __________________\n",
    "\n",
    "#### 1.3 Tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17007de",
   "metadata": {},
   "source": [
    "##### - Step 1. Visualize data and uniform it\n",
    "\n",
    "We are going to visualize some of the list of the proteins in order to see that it was downloaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I specify the path where the file of all proteins is.\n",
    "\n",
    "path_tissues = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.3.Tissues database/human_tissue_integrated_full.tsv'\n",
    "\n",
    "# We read the tsv. Tsv are limited by a t that's why it is called tsv.\n",
    "\n",
    "database_tissues = pd.read_csv(path_tissues,delimiter='\\t')\n",
    "\n",
    "# We visualize\n",
    "\n",
    "database_tissues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b217c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of entries in Tissues DB: ',len(database_tissues))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29df288",
   "metadata": {},
   "source": [
    "##### - Step 2. Find which Anatomical entity ID are from CNS. \n",
    "\n",
    "We do a filter of this file to see which proteins are from the Central Nervous System. \n",
    "\n",
    "First we go to https://www.ebi.ac.uk/ols/search?q=Central+Nervous+System&groupField=iri&start=0&ontology=uberon where the anatomical region we specified as Central Nervous System. We choose the first one \" Central Nervous System\" as it is what we want to filter. \n",
    "\n",
    "We see that the ID of the CNS is UBERON:0001017. As the list of proteins we have uses this types of ID in the column Anatomical entity ID; we want to filter this column and obtain only those genes that have this ID.\n",
    "\n",
    "Moreover, theare are some genes that are classified as brain or other CNS parts and not as CNS. So we are also interested in collecting those. We want the Anatomical entity ID of CNS and other parts of CNS. To know these parts of CNS, in the uberon ontology of CNS there is a tree with the children of CNS. \n",
    "\n",
    "**What are we going to do**\n",
    "\n",
    "Note:\n",
    "We use better the ID rathen than the Anatomical entity name cause the ID is unique and the Anatomical entity name could be free text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06797ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Given a uberon code retunr a list with all its children uberon codes\n",
    "def ols_get_code_children (uberon_code : str) -> List[str]:\n",
    "    # OLS url\n",
    "    request_url = 'https://www.ebi.ac.uk/ols/api/ontologies/bto/terms/http%253A%252F%252Fpurl.obolibrary.org%252Fobo%252F'+uberon_code+'/hierarchicalDescendants?size=1000'\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(request_url) as response:\n",
    "            parsed_response = json.loads(response.read().decode(\"utf-8\"))\n",
    "    # If the accession is not found then we can stop here\n",
    "    except urllib.error.HTTPError as error:\n",
    "        print('Error with request ' + request_url)\n",
    "        raise ValueError('Something went wrong with the PDB request (error ' + str(error.code) + ')')\n",
    "    # Mine children codes\n",
    "    embedded = parsed_response.get('_embedded', None)\n",
    "    if not embedded:\n",
    "        return []\n",
    "    children = embedded['terms']\n",
    "    child_codes = []\n",
    "    for child in children:\n",
    "        #print(child['label'])\n",
    "        child_code = child['iri'].split('/')[-1]\n",
    "        child_codes.append(child_code)\n",
    "    # Return childrn codes\n",
    "    return child_codes\n",
    "\n",
    "all_descendents = ols_get_code_children('BTO_0000227')\n",
    "#all_descendents = ['GO_0043226']\n",
    "\n",
    "    \n",
    "print(len(all_descendents))\n",
    "print(all_descendents[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcee625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the following loop in the next cell (to search the web), the codes of the UBERON have to be with _ not :\n",
    "# We change : for _\n",
    "\n",
    "all_descendents_colon= [] #New list of values with _ not :\n",
    "\n",
    "for i in range(0,len(all_descendents)): \n",
    "    all_descendents_colon.append(all_descendents[i].replace(\"_\", \":\" )) #We replace : for _ and we insert it to the list. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select those codes from the table that are children of CNS (all descendents_colon)\n",
    "\n",
    "PartsCNS_TF = database_tissues['BTO:0000000'].isin(all_descendents_colon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "PartsCNS=database_tissues[PartsCNS_TF]\n",
    "PartsCNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now select all the codes from the table that corresponds to the CNS and Whole Body: \n",
    "\n",
    "Whole_Body = database_tissues[database_tissues['BTO:0000000']=='BTO:0001489']\n",
    "CNS = Whole_Body[Whole_Body['BTO:0000000']=='BTO:0000227']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We join the two tables obtained: the one for the CNS parts (children of CNS) and the one from CNS.\n",
    "CNS_and_PartsCNS = pd.concat([CNS,PartsCNS])\n",
    "CNS_and_PartsCNS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ca94b",
   "metadata": {},
   "source": [
    "##### - Step 3. Filter those repeated.\n",
    "\n",
    "We have obtained a list which includes proteins from the Central Nervous System and all its components. However, maybe there are some repeated. We have to remove the duplications in order to have 1. \n",
    "\n",
    "We do not put any condition (prioritazing CNS e.g.) because we are only interested in those genes expressed, not other variables such as how much are expressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We filter those genes that may be repeated in the table.\n",
    "\n",
    "noduplicates= CNS_and_PartsCNS.drop_duplicates(subset=['18S_rRNA.1'])\n",
    "noduplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compare how much genes we have discarted:\n",
    "\n",
    "len(CNS_and_PartsCNS),len(noduplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe2f249",
   "metadata": {},
   "source": [
    "##### - Step 4. Uniprot overlap\n",
    "\n",
    "When doing this overlap with uniprot we are making sure that: \n",
    "\n",
    "    1. Genes codify for proteins\n",
    "    2. Genes are reviewed by Uniprot \n",
    "    \n",
    "\n",
    "We are going to map the Gene ID, which in principle it is from String; although we added also the Ensembl Protein ID to have wider results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_ENS_ID = noduplicates['18S_rRNA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3ca43c",
   "metadata": {},
   "source": [
    "Ensembl IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_ENS_ID.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.3.Tissues database/ID_Tissues_MapBy_ENSP_ouput.txt', header=None, index=None, sep=',', mode='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d2a47",
   "metadata": {},
   "source": [
    "String IDs: \n",
    "\n",
    "Here we add 9606 to the codes because for doing the mapping with Uniprot mapping tool, the String ID needs this number which identifies 'homo sapiens'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040764de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_String_ID = []\n",
    "\n",
    "for i in Gene_ENS_ID: \n",
    "    String_ID = '9606.'+i\n",
    "    Gene_String_ID.append(String_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91859aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_String_ID_dataframe = pd.DataFrame(Gene_String_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd9bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_String_ID_dataframe.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.3.Tissues database/ID_Tissues_MapBy_String_output.txt', header=None, index=None, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fce578",
   "metadata": {},
   "source": [
    "We do an intersection of String Uniprot and Ensembl Uniprot in order to not have duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Tissues_ENS = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.3.Tissues database/uniprot_MappedFromENSP_Tissues_input-2023.02.02-14.16.30.84.tsv'\n",
    "path_Tissues_STR = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.3.Tissues database/uniprot_MappedFromString_Tissues_input-2023.02.02-14.21.24.09.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tissues_STR= pd.read_csv(path_Tissues_STR,delimiter='\\t')\n",
    "Tissues_ENS = pd.read_csv(path_Tissues_ENS,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55337e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "conact_Tissues = pd.concat([Tissues_STR,Tissues_ENS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "noduplicates_concat_Tissues= conact_Tissues.drop_duplicates(subset=['Entry'])\n",
    "len(noduplicates_concat_Tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b90d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select those that are reviewed, just in case that the mapping did not choose them correctly: \n",
    "Tissues_list = noduplicates_concat_Tissues[noduplicates_concat_Tissues['Reviewed'] =='reviewed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ce7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tissues_list.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.3.Tissues database/3.Tissues_ready_output.csv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481fb068",
   "metadata": {},
   "source": [
    "#### 1.4. Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6715fb9b",
   "metadata": {},
   "source": [
    "##### - Step 1. Import the list from HPA, Tissues and Bgee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Bgee = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.1.Bgee database/1.Bgee_ready_output.csv'\n",
    "\n",
    "path_HPA = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.2.HPA database/2.HPA_ready_output.csv'\n",
    "\n",
    "path_Tissues = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.3.Tissues database/3.Tissues_ready_output.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bgee = pd.read_csv(path_Bgee,delimiter='\\t')\n",
    "\n",
    "HPA = pd.read_csv(path_HPA,delimiter='\\t')\n",
    "\n",
    "Tissues = pd.read_csv(path_Tissues,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da9342",
   "metadata": {},
   "source": [
    "Due to UniProt, some values of the entry are duplicated and I do not know why. All the duplicated values\n",
    "have the same info so we are going to eliminate one of them. This involves Tissues and Bgee lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1c151",
   "metadata": {},
   "source": [
    "##### - Step 2. Intersection between HPA-Tissues, HPA-Bgee, Bgee-Tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b147ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPA_UniprotCodes = HPA['Uniprot']\n",
    "\n",
    "Tissues_UniprotCodes = Tissues['Entry']\n",
    "\n",
    "Bgee_UniprotCodes = Bgee['Entry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListCommon_HPA_Tissues = []\n",
    "\n",
    "for i in HPA_UniprotCodes: # For each code in HPA \n",
    "    for j in Tissues_UniprotCodes: # For each code in Tissues\n",
    "        if i ==j: # If both codes are equal we append it to the list of intersection HPA-Tissues\n",
    "            ListCommon_HPA_Tissues.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b515d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListCommon_HPA_Bgee = []\n",
    "\n",
    "for i in HPA_UniprotCodes: # For each code in HPA \n",
    "    for j in Bgee_UniprotCodes: # For each code in Tissues\n",
    "        if i ==j: # If both codes are equal we append it to the list of intersection HPA-Tissues\n",
    "            ListCommon_HPA_Bgee.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListCommon_Tissues_Bgee = []\n",
    "\n",
    "for i in Bgee_UniprotCodes: # For each code in HPA \n",
    "    for j in Tissues_UniprotCodes: # For each code in Tissues\n",
    "        if i ==j: # If both codes are equal we append it to the list of intersection HPA-Tissues\n",
    "            ListCommon_Tissues_Bgee.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadf941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique UniProt entries in HPA:', len(HPA_UniprotCodes))\n",
    "\n",
    "print('Number of unique UniProt entries in Tissues:', len(Tissues_UniprotCodes))\n",
    "\n",
    "print('Number of unique UniProt entries in Bgee:', len(Bgee_UniprotCodes))\n",
    "\n",
    "\n",
    "print('Intersection length HPA-Tissues:', len(ListCommon_HPA_Tissues))\n",
    "\n",
    "print('Intersection length HPA-Bgee: ', len(ListCommon_HPA_Bgee))\n",
    "\n",
    "print('Intersection length Bgee-Tissues: ', len(ListCommon_Tissues_Bgee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_incommon_HPA_Tissues = []\n",
    "\n",
    "intersection_list = list(ListCommon_HPA_Tissues)\n",
    "\n",
    "for i in HPA_UniprotCodes:\n",
    "    if i not in intersection_list:\n",
    "        not_incommon_HPA_Tissues.append(i)\n",
    "        \n",
    "print('UniProts from HPA not in Tissues: ', len(not_incommon_HPA_Tissues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_incommon_HPA_Bgee = []\n",
    "\n",
    "intersection_list_2 = list(ListCommon_HPA_Bgee)\n",
    "\n",
    "for i in HPA_UniprotCodes:\n",
    "    if i not in intersection_list_2:\n",
    "        not_incommon_HPA_Bgee.append(i)\n",
    "\n",
    "print('UniProts from HPA not in Bgee: ', len(not_incommon_HPA_Bgee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_incommon_Bgee_Tissues = []\n",
    "\n",
    "intersection_list_3= list(ListCommon_Tissues_Bgee)\n",
    "\n",
    "for i in Bgee_UniprotCodes:\n",
    "    if i not in intersection_list_3:\n",
    "        not_incommon_Bgee_Tissues.append(i)\n",
    "\n",
    "print('UniProts from Bgee not in Tissues: ', len(not_incommon_Bgee_Tissues))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d60a83",
   "metadata": {},
   "source": [
    "##### - Step 3. Intersection between HPA and Tissues and Bgee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bgee_corrected.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bgee_UniprotCodes = Bgee['Entry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListCommon_HPA_Tissues_Bgee = []\n",
    "\n",
    "for i in ListCommon_HPA_Tissues:\n",
    "    for j in Bgee_UniprotCodes: \n",
    "        if i ==j: \n",
    "            ListCommon_HPA_Tissues_Bgee.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c538c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intersection length HPA-Tissues-Bgee:', len(ListCommon_HPA_Tissues_Bgee))\n",
    "\n",
    "print('Intersection length HPA-Tissues:', len(ListCommon_HPA_Tissues))\n",
    "\n",
    "print('Length HPA:', len(HPA_UniprotCodes))\n",
    "\n",
    "print('Length Tissues:', len(Tissues_UniprotCodes))\n",
    "\n",
    "print('Length Bgee:', len(Bgee_UniprotCodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb82e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do a definitive list from the  3 UniProt list acquired from the 3 DBs and UniProt DB\n",
    "#: it'll be a list from Uniprot:\n",
    "Lista_Uniprot_fromTissues = Tissues['Entry'].isin(ListCommon_HPA_Tissues_Bgee)\n",
    "Lista_Uniprot=Tissues[Lista_Uniprot_fromTissues]\n",
    "len(Lista_Uniprot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a636424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the list of the intersection. \n",
    "# This list contains CNS proteins.\n",
    "Lista_Uniprot.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.4.Overlap/IntersectionListCNS.csv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256902c1",
   "metadata": {},
   "source": [
    "# ___________\n",
    "# ___________ \n",
    "\n",
    "### 2. FILTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78de51",
   "metadata": {},
   "source": [
    "#### 2.1. Drug Targetable. Opentargets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5a5f8",
   "metadata": {},
   "source": [
    "##### A. Druggable with small molecule activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a06c6",
   "metadata": {},
   "source": [
    "We are going to get from pharos the datasets: \n",
    "    Tchem: \n",
    "    Tclin: \n",
    "        \n",
    "This will give us the targets which have an Approved Drug and Ligand binding sites. \n",
    "\n",
    "We are going to get from Open Targets: \n",
    "    High-Quality Pocket: Target has a DrugEBIlity score of ≥ 0.7 \n",
    "    \n",
    "This will give us the targets whose scoring is bigger than 0.7.  The scoring is based on the conformational state of the protein structure that is analysed, if there is potentially an induced, or cryptic 'drugable' site. Finally, bear in mind that it is a statistical method, with some error, it is not meant to be definitive, but acts as a guide. -> http://chembl.github.io/drugebility-structure-based-component/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0947d",
   "metadata": {},
   "source": [
    "###### - Step 1. Collect data from Pharos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce3891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "path_pharos = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.1.Opentarget/Drug_SmallMolec/pharos_data_download/query results.csv'\n",
    "\n",
    "pharos = pd.read_csv(path_pharos,delimiter=',')\n",
    "\n",
    "pharos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length *unique* values of UniProt column: ', len(pd.unique(pharos['UniProt'])), '. Length values of Uniprot column: ', len(pharos['UniProt']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprots_pharos = list(pharos['UniProt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa3486e",
   "metadata": {},
   "source": [
    "##### - Step 2. Collect data from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64231c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We open the data Open Targets gives us: \n",
    "#This data is the targets in general.\n",
    "\n",
    "lista_pandas = []\n",
    "\n",
    "for num in range(200): \n",
    "    if len(str(num)) == 1: \n",
    "        num_def = '0000'+str(num)\n",
    "        \n",
    "    if len(str(num)) == 2: \n",
    "        num_def = '000'+str(num)\n",
    "        \n",
    "    if len(str(num)) == 3: \n",
    "        num_def = '00'+str(num)\n",
    "        \n",
    "    \n",
    "    path = '/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.1.Opentarget/Drug_SmallMolec/targets/part-'+num_def+'-55bc3d37-90ad-48ea-a5a2-de8d3b646beb-c000.json'\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        raw = file.read()\n",
    "\n",
    "    raw = raw.replace('\\n',',')\n",
    "    raw = '[' + raw[:-1] + ']'\n",
    "\n",
    "    test_json = '/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.1.Opentarget/Drug_SmallMolec/targets/test.json'\n",
    "    with open(test_json, 'w') as file:\n",
    "        file.write(raw)\n",
    "    \n",
    "    with open(test_json, 'r') as file:\n",
    "        datos = json.load(file)\n",
    "    \n",
    "    df = pd.DataFrame(datos)\n",
    "    lista_pandas.append(df)\n",
    "\n",
    "lista_opentarget = pd.concat(lista_pandas)\n",
    "\n",
    "lista_opentarget.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f599ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by protein coding. \n",
    "\n",
    "proteincoding_opentarget = lista_opentarget[lista_opentarget['biotype'] == 'protein_coding']\n",
    "\n",
    "# Almost all the proteins here are 'considered targetable'. This is inexact as OpenTargets includes all proteins\n",
    "# and then it specifiys which one are targetable (druggable, etc.). This is seen in the column tractability. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56082b",
   "metadata": {},
   "source": [
    "*OT: Filter by small molecules: High-Quality Pocket: Target has a DrugEBIlity score of ≥ 0.7*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We filter by these ones in the column tractabiliy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tractability = proteincoding_opentarget['tractability'] # We extract the tractability column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_modalities = ['SM']\n",
    "accepted_ids = ['Approved Drug', 'Advanced Clinical', 'Phase 1 Clinical', 'High-Quality Pocket']\n",
    "druggable_SM_ligands = pd.DataFrame(columns = proteincoding_opentarget. columns. values) # New dataframe to append all \n",
    "                                                                                         # druggable by small molecule activity. \n",
    "count = 0\n",
    "m = -1 # It will be the index of the dataframe\n",
    "list_id = []\n",
    "\n",
    "for target in tractability: # For each element (list of dictionaries) of the list tractability created in the above cell\n",
    "    m += 1 \n",
    "    \n",
    "    if type(target) != list and pd.isnull(target): continue # To avoid Nan values that may do this loop fail.\n",
    "        \n",
    "    for entry in target: # For each dictionary\n",
    "        if entry['modality'] not in accepted_modalities: # If the value of the modality key is not in the accepted modalities list above described: \n",
    "            continue # We skip the current iteration\n",
    "        if entry['id'] not in accepted_ids: # If the value of the id key is not in the accepted ids list above described:\n",
    "            continue # We skip the current iteration\n",
    "            \n",
    "        # If entry[modality] is in accepted_modalities  and entry['id'] is in accepted_ids:  \n",
    "        if entry['value'] == True: # Then if the value of the value key is True: \n",
    "            idx = m\n",
    "            ids = str(proteincoding_opentarget.iloc[[idx]]['id']).split()[1]#\n",
    "            row_to_append = proteincoding_opentarget.iloc[[idx]] # We indicate which row has to be appended\n",
    "            druggable_SM_ligands = pd.concat([druggable_SM_ligands,row_to_append])# We add the row to the dataframe we have created. \n",
    "            list_id.append(ids) # We append the value of the id column \n",
    "            break # We break the most internal loop in order to avoid duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of genes considered to be druggable (fact or potentially) by Small Molecules: ', len(druggable_SM_ligands)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "druggable_SM_ligands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check that we have in the above dataframe no duplicates of id\n",
    "len(pd.unique(druggable_SM_ligands['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the UniProt codes of the above table.\n",
    "\n",
    "uniprots_OT = []\n",
    "protein_id_OT = druggable_SM_ligands['proteinIds'] # We get the 'proteinIds' of each 'id'\n",
    "\n",
    "for i in protein_id_OT: \n",
    "    for y in i: \n",
    "        if y['source'] =='uniprot_swissprot': # We select only those UniProt IDs that its source is swissprot. \n",
    "            uniprot = y['id']\n",
    "            uniprots_OT.append(uniprot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58680aea",
   "metadata": {},
   "source": [
    "##### Step 3. Intersection between data from Pharos and OpenTargets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the intersection between Pharos and Open Targets\n",
    "\n",
    "uniprots_druggable = []\n",
    "\n",
    "for i in uniprots_OT: # uniprots_OT contain unique uniprots values\n",
    "    for j in uniprots_pharos: # uniprots_pharos contain unique uniprots values\n",
    "        if i==j:\n",
    "            uniprots_druggable.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of UniProts from intersection between Pharos and Open Targets: ', len(uniprots_druggable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get a list of unique values: \n",
    "\n",
    "Uniprot_SM_pocket_ligand = list(set(uniprots_druggable))\n",
    "print('Number of *unique* UniProts from intersection between Pharos and Open Targets: ', len(Uniprot_SM_pocket_ligand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b2a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the CNS proteins list\n",
    "\n",
    "path_intersectionlist='~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/1. Lists CNS/1.4.Overlap/IntersectionListCNS.csv'\n",
    "\n",
    "IntersectionList= pd.read_csv(path_intersectionlist, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfbfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see which proteins from the CNS protein list are targets; considering target\n",
    "# as druggable by Small Molecule activity.\n",
    "\n",
    "Common_OpenTarget_IntersectionList = []\n",
    "\n",
    "for i in Uniprot_SM_pocket_ligand:\n",
    "    for j in IntersectionList['Entry']: \n",
    "        if i ==j: \n",
    "            Common_OpenTarget_IntersectionList.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22026e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of entries (UniProts) in Open Targets filtered by druggable by SM:',len(Uniprot_SM_pocket_ligand))\n",
    "print('Number of entries (UniProts) in the CNS protein list :',len(IntersectionList))\n",
    "print('Number of entries (UniProts) Open Targets-CNS protein list:',len(Common_OpenTarget_IntersectionList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the UniProt table by selecting only those that are in the intersection\n",
    "# between Open Targets and the CNS protein list. \n",
    "\n",
    "List_OpenTarg_IntersectionCNS_values = IntersectionList['Entry'].isin(Common_OpenTarget_IntersectionList)\n",
    "List_OpenTarg_IntersectionCNS=IntersectionList[List_OpenTarg_IntersectionCNS_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff6e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the above table\n",
    "\n",
    "List_OpenTarg_IntersectionCNS.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.1.Opentarget/Drug_SmallMolec/OT_druggable_SM.csv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e242c",
   "metadata": {},
   "source": [
    "#### B. Parkinson Diseases targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba385815",
   "metadata": {},
   "source": [
    "##### - Step 1. Collect data from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lista_pandas = []\n",
    "\n",
    "for num in range(200): \n",
    "    if len(str(num)) == 1: \n",
    "        num_def = '0000'+str(num)\n",
    "        \n",
    "    if len(str(num)) == 2: \n",
    "        num_def = '000'+str(num)\n",
    "        \n",
    "    if len(str(num)) == 3: \n",
    "        num_def = '00'+str(num)\n",
    "        \n",
    "    \n",
    "    path = '/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.1.Opentarget/Drug_SmallMolec/associationByOverallDirect/part-'+num_def+'-f0677964-d777-4ff4-86c4-c2f82df76b23-c000.json'\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        raw = file.read()\n",
    "\n",
    "    raw = raw.replace('\\n',',')\n",
    "    raw = '[' + raw[:-1] + ']'\n",
    "\n",
    "    test_json = '/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.1.Opentarget/Drug_SmallMolec/associationByOverallDirect/test.json'\n",
    "    with open(test_json, 'w') as file:\n",
    "        file.write(raw)\n",
    "    \n",
    "    with open(test_json, 'r') as file:\n",
    "        datos = json.load(file)\n",
    "    \n",
    "    df = pd.DataFrame(datos)\n",
    "    lista_pandas.append(df)\n",
    "    \n",
    "lista_opentarget_diseases = pd.concat(lista_pandas)\n",
    "print('Number of entries in the Open Targets Disease DB: ', len(lista_opentarget_diseases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We filter by MONDO ontology: Parkinson Disease: MONDO_0005180\n",
    "\n",
    "PD = lista_opentarget_diseases[lista_opentarget_diseases['diseaseId'] == 'MONDO_0005180']\n",
    "\n",
    "print('Number of entries in the Open Targets DB filtered by Parkinson Disease: ', len(PD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96342340",
   "metadata": {},
   "outputs": [],
   "source": [
    "PD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48556946",
   "metadata": {},
   "outputs": [],
   "source": [
    "PD['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf10955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We are going to set a threshold value in order to have strong evidences that that target is for the Parkinson's Disease\n",
    "\n",
    "# To do this, first we are going to normalize all the values \n",
    "\n",
    "list_scores = list(PD['score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0137187",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_normscores_dict= {} # We create a dictionary because of the float problem\n",
    "norm_scores =[] # Normalized scores will be inside here also\n",
    "\n",
    "for score in list_scores: \n",
    "    \n",
    "    norm_score = score/ max(list_scores)\n",
    "    score_normscores_dict[score] = norm_score\n",
    "    \n",
    "    norm_scores.append(norm_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2636f33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.hist(norm_scores, bins=20)\n",
    "\n",
    "plt.title('Histogram of frequency of normalized scores for Parkinsons Disease')\n",
    "plt.ylabel('Number of score values')\n",
    "plt.xlabel('Normalized score value')\n",
    "\n",
    "plt.ylim(0,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ac3f7",
   "metadata": {},
   "source": [
    "From this plot we see that the majority of the norm scores are between ~0 and 0.2. This means that they have very little evidence because maybe the are few sources that have studied this target. \n",
    "We see that from 0.4 upwards there are some scores. We can consider that 0.5 in norm data is quite of reliable as  it is the half of the maximum score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_scores_05 = [i for i in norm_scores if i > 0.5]\n",
    "\n",
    "print('Number of scores for PD that have a normalized score bigger than 0.5: ', len(norm_scores_05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_05 = []\n",
    "\n",
    "for score_dicti in score_normscores_dict: # For each normalized value of PD score\n",
    "    score_dicti_norm = score_normscores_dict[score_dicti] \n",
    "    \n",
    "    if score_dicti_norm in norm_scores_05: # If this value is in the list of scores above 0.5\n",
    "        scores_05.append(score_dicti) # Append to a list where there will be the interesting ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d64542",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eccd61d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_05_unique = list(set(scores_05))\n",
    "\n",
    "print('Number of unique scores above 0.5 of their normalized value: ', len(scores_05_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "PD_scorefilter = pd.DataFrame(columns = PD. columns. values) # We create new dataframe to append those targets with\n",
    "                                                            # a normalized score bigger than 0.5\n",
    "\n",
    "for i in scores_05_unique: \n",
    "    row_to_append = PD[PD['score'] == i]\n",
    "    PD_scorefilter = pd.concat([PD_scorefilter,row_to_append])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b3c97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Dataframe for Parkinsons Diease targets with a normalized score bigger than 0.5: ')\n",
    "PD_scorefilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840414a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PD_scorefilter_id_2 = PD_scorefilter['targetId'] # We get the target IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PD_scorefilter_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PD_scorefilter_id = PD_scorefilter['targetId'] # We get the target IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_PD = []\n",
    "\n",
    "for i in PD_scorefilter_id_2: \n",
    "    protein_ids = proteincoding_opentarget[proteincoding_opentarget['id'] == i]['proteinIds']\n",
    "    for j in protein_ids: \n",
    "        for m in j:\n",
    "            if m['source'] =='uniprot_swissprot': # We get the UniProt ID for the specific ENSG ID \n",
    "                uniprot = m['id']\n",
    "                uniprot_PD.append(uniprot)\n",
    "            if 'uniprot_swissprot' not in str(list(protein_ids)):\n",
    "                print('These do not have a UniProt ID: ',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b28ccc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(uniprot_PD) # Two do not have a uniprot_swissprot source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0ef15",
   "metadata": {},
   "source": [
    "#### C. Intersection between Pharos-OpenTargets Targets and OpenTargets Associations: Druggable with SM activity - Parkinson Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_druggable_PD = []\n",
    "\n",
    "for i in Uniprot_SM_pocket_ligand: # We do the intersection between the targetable by druggable by Small Molecule activity \n",
    "    if i in uniprot_PD:  # and the targetable for Parkinsons Disease\n",
    "        uniprot_druggable_PD.append(i) # The common ones, we append it to a list \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uniprot_druggable_PD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea964636",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common_OpenTarget_IntersectionList = []\n",
    "\n",
    "for i in uniprot_druggable_PD:\n",
    "    for j in IntersectionList['Entry']: \n",
    "        if i ==j: \n",
    "            Common_OpenTarget_IntersectionList.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c34557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of UniProts Druggable by SM and PD :',len(uniprot_druggable_PD))\n",
    "print('Number of UniProts from the CNS protein list:',len(IntersectionList))\n",
    "print('Number of UniProts from CNS and Targetable:',len(Common_OpenTarget_IntersectionList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880781cd",
   "metadata": {},
   "source": [
    "#### D. Intersection between druggable with SM activity for PD and CNS protein list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_OpenTarg_IntersectionCNS_values = IntersectionList['Entry'].isin(Common_OpenTarget_IntersectionList)\n",
    "List_OpenTarg_IntersectionCNS=IntersectionList[List_OpenTarg_IntersectionCNS_values]\n",
    "len(List_OpenTarg_IntersectionCNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_OpenTarg_IntersectionCNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c681337",
   "metadata": {},
   "source": [
    "##### Save list of CNS proteins that are targetable for SM for PD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a197b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_OpenTarg_IntersectionCNS.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.1.Opentarget/Drug_SmallMolec/OT_PD_druggable_SM_correct.csv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e720fd",
   "metadata": {},
   "source": [
    "# ___________\n",
    "\n",
    "#### 2.2. Membrane. Uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b8a02",
   "metadata": {},
   "source": [
    "##### - Step 1. Import data from UniProt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a33492e",
   "metadata": {},
   "source": [
    "We import the list from Uniprot including Transmembrane and Intermembrane proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227132fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Uniprot_Membrane = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.2.Membrane_Uniprot/uniprot-compressed_true_download_true_fields_accession_2Creviewed_2C-2023.02.06-12.46.59.48.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570eddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_Membrane = pd.read_csv(path_Uniprot_Membrane,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_intersectionlist_optarg='~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.1.Opentarget/Drug_SmallMolec/OT_PD_druggable_SM_correct.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "IntersectionListOptarg= pd.read_csv(path_intersectionlist_optarg,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e1b8a1",
   "metadata": {},
   "source": [
    "##### - Step 2. Intersection between CNS target proteins and membrane proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common_MembIntermemb_IntersectionList = []\n",
    "\n",
    "for i in Uniprot_Membrane['Entry']: # For each code of Uniprot_Membrane (Uniprot codes with membrane domains)\n",
    "    for j in IntersectionListOptarg['Entry']: # For each code of IntersectionList (Uniprot code of CNS list)\n",
    "        if i ==j: # If they are equal\n",
    "            Common_MembIntermemb_IntersectionList.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of UniProts which are Membrane proteins:',len(Uniprot_Membrane))\n",
    "print('Number of UniProts which are CNS Targetable proteins (with some filters):',len(IntersectionListOptarg))\n",
    "print('Number of UniProts which are CNS Targetable Membrane proteins:',len(Common_MembIntermemb_IntersectionList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537424a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We only select those proteins from the CNS list that are inter/trans membrane\n",
    "\n",
    "List_Membr_IntersectionCNS_values = IntersectionList['Entry'].isin(Common_MembIntermemb_IntersectionList)\n",
    "List_Membr_IntersectionCNS=IntersectionList[List_Membr_IntersectionCNS_values]\n",
    "len(List_Membr_IntersectionCNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c1763",
   "metadata": {},
   "source": [
    "##### - Step 3. Save the list for CNS target membrane proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13310079",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Membr_IntersectionCNS.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.2.Membrane_Uniprot/List_CNS_DruggablePD_Mem_Uniprot_correct.csv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb391f95",
   "metadata": {},
   "source": [
    "# ______\n",
    "\n",
    "#### 2.3. Length sequence > 100 aa. Uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f4c522",
   "metadata": {},
   "source": [
    "##### - Step 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32192bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Membrane_CNS_path= '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.2.Membrane_Uniprot/List_CNS_DruggablePD_Mem_Uniprot_correct.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Membrane_CNS=pd.read_csv(Membrane_CNS_path,delimiter='\\t')\n",
    "\n",
    "Membrane_CNS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83188aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CNS Targetable Membrane proteins: ',len(Membrane_CNS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53adbb41",
   "metadata": {},
   "source": [
    "##### - Step 2. Cut-off length aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4945695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of the lengths of each protein\n",
    "Length_aa = Membrane_CNS['Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get useful information of the Length column in order to set a cut-off\n",
    "Length_aa.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85679625",
   "metadata": {},
   "source": [
    "We create a frequency table to know which intervals are more frequent and examine the structure of the protein and see if it has an interesting one (different chains, etc) or a simple one (one helix alpha...) so it is not that much interesting for studying its dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = (Length_aa.max()-Length_aa.min())/200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abs_frecuency, intervals = np.histogram(Length_aa, bins = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "freq_table = pd.DataFrame(index = np.linspace(1,100,100), columns = ['start', 'end', 'class_marks','Frec_abs'])\n",
    "# Assign the intervals\n",
    "freq_table['start'] = intervals[:-1]\n",
    "freq_table['end'] = intervals[1:]\n",
    "# Calculate class marks\n",
    "freq_table['class_marks'] = (freq_table['start'] + freq_table['end'])/2\n",
    "# Assing Absolute frecuency\n",
    "freq_table['Frec_abs'] = Abs_frecuency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621dc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09933cc3",
   "metadata": {},
   "source": [
    "# ____\n",
    "\n",
    "#### 2.4. With PDB structure \n",
    " When we have already done filter of length aa of the membrane-intersection cns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066d80a9",
   "metadata": {},
   "source": [
    "##### - Step 1. Filter those proteins that have PDB structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the list of the filtered length of the aminoacids. \n",
    "\n",
    "filter_length = pd.read_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.2.Membrane_Uniprot/List_CNS_DruggablePD_Mem_Uniprot_correct.csv',delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cf31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the Uniprot codes ('Entry')\n",
    "Uniprot_codes = filter_length['Entry'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa1e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the document proportionated by lab of P.Aloy\n",
    "uniprot = pd.read_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Angelo_Alloy_Proteins/uniprot_pdb.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do a table of those Uniprot_codes that are found in the SP_PRIMARY column of the file uniprot_pdb\n",
    "table_PDBs_CNS = uniprot[uniprot['SP_PRIMARY'].isin(Uniprot_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the columns of the table\n",
    "table_PDBs_CNS.columns=['Uniprot','PDB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da354c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the values\n",
    "table_PDBs_CNS['gene_name']=[filter_length[filter_length['Entry']==x]['Gene Names'].to_list()[0] for x in table_PDBs_CNS['Uniprot'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the final table where we have all the PDBs codes for each Uniprot belonging to CNS, membrane and length > 100 aa\n",
    "table_PDBs_CNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3cbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have: ',len(filter_length),' CNS Targetable Membrane proteins\\nWe have: ',len(table_PDBs_CNS),' proteins with PDB structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('We have: ',len(filter_length),' CNS Targetable Membrane proteins\\nWe have: ',len(table_PDBs_CNS),' proteins with PDB structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now extract all the PDBs codes that we have: \n",
    "\n",
    "PDBs_CNS_possibleduplicates = [] # There may be some duplicates.\n",
    "table_PDB = list(table_PDBs_CNS['PDB']) \n",
    "\n",
    "for i in table_PDB: \n",
    "    if ';' in i: \n",
    "        for item in i.split(\";\"):# We split those values that are in the same row.\n",
    "            PDBs_CNS_possibleduplicates.append(item)      \n",
    "    else: \n",
    "        PDBs_CNS_possibleduplicates.append(i) #If there are not values in the same row, then we append it as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1607b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now get rid of the duplicates\n",
    "\n",
    "PDBs_CNS = []\n",
    "\n",
    "for item in PDBs_CNS_possibleduplicates:\n",
    "    if item not in PDBs_CNS:\n",
    "        PDBs_CNS.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of PDBs that are from the CNS, Targets, Membrane,length>100, possible dupli:  ',len(PDBs_CNS_possibleduplicates),'PDBs')\n",
    "print('Number of PDBs that are from the CNS, Targets, Membrane:  ',len(PDBs_CNS),'PDBs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747553f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Number of PDBs that are from the CNS, membrane and with a length >100, possible dupli:  ',len(PDBs_CNS_possibleduplicates),'PDBs')\n",
    "#print('Number of PDBs that are from the CNS, membrane and with a length >100:  ',len(PDBs_CNS),'PDBs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the table\n",
    "#print('Total number of proteins from CNS, membrane, length>100, with PDB structure_possidupli:',len(table_PDBs_CNS), 'proteins')\n",
    "#print('Number of PDBs that are from the CNS, membrane and with a length >100, possible dupli:  ',len(PDBs_CNS_possibleduplicates),'PDBs')\n",
    "#print('Total number of PDBs, without dupli: ', len(PDBs_CNS), 'PDBs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc328b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Length of the table\n",
    "print('Total number of proteins from CNS, Targets, Membrane, length>100, PDB structure, possidupli:',len(table_PDBs_CNS), 'proteins')\n",
    "print('Number of PDBs that are from the CNS, Targets, Membrane, length>100, possible dupli:  ',len(PDBs_CNS_possibleduplicates),'PDBs')\n",
    "print('Total number of PDBs from CNS, Targets, Membrane, >100 aa proteins, without dupli: ', len(PDBs_CNS), 'PDBs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_PDBs_CNS.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.4.PDB/List_CNS_DruggablePD_Mem_100aa_PDB_Uniprot.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_PDBs_CNS.to_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.4.PDB/List_CNS_DruggablePD_Mem_100aa_PDB_Uniprot_correct.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b24482",
   "metadata": {},
   "source": [
    "#### 2.4.1. Information about PDB structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23539b7",
   "metadata": {},
   "source": [
    "##### Split PDBs and make a table of keys: Uniprot and PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a85855",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_PDBs_CNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfdefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_id_dict = [] # We create a list of the multiple Uniprot for each PDB that exists\n",
    "\n",
    "for PDB_id in list(table_PDBs_CNS['PDB']): # For each PDB (can be multiple PDBs)\n",
    "    count_char = PDB_id.count(';')+1 # We count how many PDBs are in that string, the codes are split with ;\n",
    "    \n",
    "    idx = table_PDBs_CNS[table_PDBs_CNS['PDB'] == PDB_id].index.tolist() # We calculate the index of that PDB\n",
    "    \n",
    "    if PDB_id ==  list(table_PDBs_CNS.loc[idx[0]])[1]: # If the PDB string is equal to the value of PDBs in the row of the index\n",
    "        Unid_multiple = (table_PDBs_CNS.loc[idx[0]][0],)*count_char # Then we multiply the id of Uniprot the number of times of PDB codes in that string\n",
    "        Uniprot_id_dict.append(Unid_multiple) # We save the value in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_id_dict_nottuple = []\n",
    "\n",
    "for Uniprot_id_dict_tuple in Uniprot_id_dict: \n",
    "    for Uniprot_id_indi in Uniprot_id_dict_tuple: \n",
    "        Uniprot_id_dict_nottuple.append(Uniprot_id_indi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d02f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "genename_dict = [] # We create a list of the multiple genename for each PDB that exists\n",
    "\n",
    "for PDB_id in list(table_PDBs_CNS['PDB']): # For each PDB (can be multiple PDBs)\n",
    "    count_char = PDB_id.count(';')+1 # We count how many PDBs are in that string, the codes are split with ;\n",
    "    \n",
    "    idx = table_PDBs_CNS[table_PDBs_CNS['PDB'] == PDB_id].index.tolist() # We calculate the index of that PDB\n",
    "    \n",
    "    if PDB_id ==  list(table_PDBs_CNS.loc[idx[0]])[1]: # If the PDB string is equal to the value of PDBs in the row of the index\n",
    "        genename_multiple = (table_PDBs_CNS.loc[idx[0]][2],)*count_char # Then we multiply the id of genename the number of times of PDB codes in that string\n",
    "        genename_dict.append(genename_multiple) # We save the value in the list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f20e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genename_dict_nottuple = []\n",
    "\n",
    "for genename_dict_tuple in genename_dict: \n",
    "    for genename_indi in genename_dict_tuple: \n",
    "        genename_dict_nottuple.append(genename_indi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Uniprot_id_dict_nottuple),len(PDBs_CNS_possibleduplicates),len(genename_dict_nottuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Uniprot':Uniprot_id_dict_nottuple,'PDB':PDBs_CNS_possibleduplicates,'gene_name':genename_dict_nottuple}\n",
    "table_PDBs = pd.DataFrame.from_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb582f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_PDBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table_PDBs['PDB'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d29244",
   "metadata": {},
   "source": [
    "##### API to get more info\n",
    "\n",
    "To get the information about the **experimental method** of each PDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "from typing import List\n",
    "\n",
    "# Given a pdb Id, get its Experimental Obtaining Method\n",
    "\n",
    "def pdb_info_exp (pdb_id : str) -> List[str]:\n",
    "    # Request the MMB service to retrieve pdb data\n",
    "    request_url = 'https://mmb.irbbarcelona.org/api/pdb/' + pdb_id + '/entry'\n",
    "    try:\n",
    "        with urllib.request.urlopen(request_url) as response:\n",
    "            parsed_response = json.loads(response.read().decode(\"utf-8\"))\n",
    "    # If the accession is not found in the PDB then we can stop here\n",
    "    except urllib.error.HTTPError as error:\n",
    "        if error.code == 404:\n",
    "            return None\n",
    "        else:\n",
    "            raise ValueError('Something went wrong with the PDB request: ' + request_url)\n",
    "    # Get the uniprot accessions\n",
    "    pdb_expType = parsed_response['expType'] # We get the Experimental Method\n",
    "    \n",
    "    return pdb_expType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e08a50",
   "metadata": {},
   "source": [
    "To get the information about the **experimental resolution** of each PDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "from typing import List\n",
    "\n",
    "# Given a pdb Id, get its method resolution\n",
    "\n",
    "def pdb_info_resol (pdb_id : str) -> List[str]:\n",
    "    # Request the MMB service to retrieve pdb data\n",
    "    request_url = 'https://mmb.irbbarcelona.org/api/pdb/' + pdb_id + '/entry'\n",
    "    try:\n",
    "        with urllib.request.urlopen(request_url) as response:\n",
    "            parsed_response = json.loads(response.read().decode(\"utf-8\"))\n",
    "    # If the accession is not found in the PDB then we can stop here\n",
    "    except urllib.error.HTTPError as error:\n",
    "        if error.code == 404:\n",
    "            return None\n",
    "        else:\n",
    "            raise ValueError('Something went wrong with the PDB request: ' + request_url)\n",
    "    # Get the uniprot accessions\n",
    "    pdb_resol= parsed_response['resol'] # We get the resolution \n",
    "    return pdb_resol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c66eda",
   "metadata": {},
   "source": [
    "To get the information about the **information about chains: type, sequence, fragments** of each PDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdec103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "from typing import List\n",
    "\n",
    "# Given a pdb Id, gets information of each of its chains. \n",
    "\n",
    "def pdb_info_chains (pdb_id : str) -> List[str]:\n",
    "    # Request the MMB service to retrieve pdb data\n",
    "    request_url = 'https://mmb.irbbarcelona.org/api/pdb/' + pdb_id + '/entry'\n",
    "    try:\n",
    "        with urllib.request.urlopen(request_url) as response:\n",
    "            parsed_response = json.loads(response.read().decode(\"utf-8\"))\n",
    "    # If the accession is not found in the PDB then we can stop here\n",
    "    except urllib.error.HTTPError as error:\n",
    "        if error.code == 404:\n",
    "            return None\n",
    "        else:\n",
    "            raise ValueError('Something went wrong with the PDB request: ' + request_url)\n",
    "    \n",
    "    # Get the uniprot accessions\n",
    "    if parsed_response['chainIds'] != None: # If there are ChainIds: \n",
    "        \n",
    "        chains = [ chain[-1] for chain in parsed_response['chainIds'] ] \n",
    "        # We only stay with the last letter of the chain because it indicates the chain type\n",
    "        \n",
    "\n",
    "        id_chains = [ chain['_id'] for chain in parsed_response['chains'] ]\n",
    "        # We get all the id of the chain \n",
    "        \n",
    "        sequence_uniprot = [ chain['sequence'] for chain in parsed_response['chains']]\n",
    "        # We get the sequence of Uniprot of each chaine if each PDB has different chains. \n",
    "        \n",
    "        \n",
    "        # To get the fragments we do not do a compressed loop: \n",
    "        fragments_all = [] # We create a list to put all the fragments of all chains here\n",
    "        \n",
    "        \n",
    "        for chain in parsed_response['chains']: # We get the fragments of each chain\n",
    "            if chain['PDBSequence'] != None: # as long as the PDBSequence exists because if not, we would not have fragments\n",
    "                fragments = chain['PDBSequence']['fragments'] \n",
    "                fragments_all.append(fragments)\n",
    "\n",
    "                \n",
    "                \n",
    "        # We want a dictionary with: being the key the chain type ['A'], and the values all the information of\n",
    "        #this chain for this PDB ex. sequence['AGJEROW'], fragments ['1-22, 133-159']. \n",
    "        lista_dicti = []\n",
    "        \n",
    "        \n",
    "        for idx in (range(len(chains))):\n",
    "            if chain['PDBSequence'] != None: # as long as it exists a PDBSequence\n",
    "                print(id_chains[idx])\n",
    "                dicti = {chains[idx]:[sequence_uniprot[idx],fragments_all[idx]]}\n",
    "                lista_dicti.append(dicti)\n",
    "\n",
    "        return lista_dicti\n",
    "    \n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d233a33",
   "metadata": {},
   "source": [
    "To get the information about the **Chain ID (type)** of each PDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3132018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "from typing import List\n",
    "\n",
    "# Given a pdb Id, get its identifiers chains: \n",
    "\n",
    "def pdb_chains (pdb_id : str) -> List[str]:\n",
    "    # Request the MMB service to retrieve pdb data\n",
    "    request_url = 'https://mmb.irbbarcelona.org/api/pdb/' + pdb_id + '/entry'\n",
    "    try:\n",
    "        with urllib.request.urlopen(request_url) as response:\n",
    "            parsed_response = json.loads(response.read().decode(\"utf-8\"))\n",
    "    # If the accession is not found in the PDB then we can stop here\n",
    "    except urllib.error.HTTPError as error:\n",
    "        if error.code == 404:\n",
    "            return None\n",
    "        else:\n",
    "            raise ValueError('Something went wrong with the PDB request: ' + request_url)\n",
    "    \n",
    "    # Get the uniprot accessions\n",
    "    if parsed_response['chainIds'] != None: \n",
    "        \n",
    "        chains = [ chain[-1] for chain in parsed_response['chainIds'] ]\n",
    "        #Here we only get the last letter of the chain id because faster than mining the previous dictionary. \n",
    "\n",
    "        return chains\n",
    "    \n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53235c68",
   "metadata": {},
   "source": [
    "We run each function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d30f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdb_info_exp_list = []\n",
    "\n",
    "for PDB_id in table_PDBs['PDB']: \n",
    "    if PDB_id not in pdb_info_exp_list:\n",
    "        pdb_info_api = pdb_info_exp(PDB_id)\n",
    "        print(pdb_info_api)\n",
    "        pdb_info_exp_list.append(pdb_info_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9f563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdb_info_resol_list = []\n",
    "\n",
    "for PDB_id in table_PDBs['PDB']:\n",
    "    if PDB_id not in pdb_info_resol_list:\n",
    "        pdb_info_resol_api = pdb_info_resol(PDB_id)\n",
    "        print(pdb_info_resol_api)\n",
    "        pdb_info_resol_list.append(pdb_info_resol_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e678394",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_info_chains_list = []\n",
    "\n",
    "for PDB_id in table_PDBs['PDB']: \n",
    "    pdb_info_chain_api = pdb_info_chains(PDB_id)\n",
    "    print(pdb_info_chain_api)\n",
    "    pdb_info_chains_list.append(pdb_info_chain_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5477f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdb_chains_list = []\n",
    "\n",
    "for PDB_id in table_PDBs['PDB']: \n",
    "    pdb_chain_api = pdb_chains(PDB_id)\n",
    "    print(pdb_chain_api)\n",
    "    pdb_chains_list.append(pdb_chain_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2146674",
   "metadata": {},
   "source": [
    "We create the table of all the things above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Uniprot':Uniprot_id_dict_nottuple,'PDB':PDBs_CNS_possibleduplicates,'Chains':pdb_chains_list,'Info Chains: chain, seq, fragments':pdb_info_chains_list,'Experimental method':pdb_info_exp_list,'Experimental Resolution':pdb_info_resol_list,'gene_name':genename_dict_nottuple}\n",
    "table_proteins_PDB_CNS_membrane_l100 = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261fc3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100.to_csv('PD_0_NOT_and_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100_correct.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_proteins_PDB_CNS_membrane_l100.to_csv('PD_0_NOT_and_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100 = pd.read_csv('PD_0_NOT_and_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78334d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb66c14",
   "metadata": {},
   "source": [
    "##### Review they are from CNS\n",
    "\n",
    "We are going to review it with the HPA brain database, although Bgee and Tissues also would work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HPA_raw = pd.read_csv('~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/2.HPA/NOT.tsv',delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0740a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_HPA = HPA_raw['Uniprot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fef2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_df_notunique = table_proteins_PDB_CNS_membrane_l100['Uniprot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15372cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_values(x):\n",
    "    return list(dict.fromkeys(x))\n",
    "\n",
    "Uniprot_df_unique = unique_values(table_proteins_PDB_CNS_membrane_l100['Uniprot'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7033f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for i in Uniprot_df_unique:\n",
    "    if i in list(Uniprot_HPA):\n",
    "        n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('If the workflow was well done, all the proteins that we have in our list df should be from the CNS,and therefore\\nshould be in the HPA')\n",
    "print()\n",
    "print('This means that the length of the unique Uniprot values of our list should be equal to the ones of this list into\\nthe HPA brain database ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32bd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Uniprot_df_unique: ',len(Uniprot_df_unique),'\\nNumber of proteins found in HPA: ',n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94292987",
   "metadata": {},
   "source": [
    "# ______\n",
    "\n",
    "#### 2.5. In MemProtMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0070520",
   "metadata": {},
   "source": [
    "##### API to know all info contained in MemprotMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e10f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMPROTMD_ROOT_URI = \"http://memprotmd.bioch.ox.ac.uk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of function to collect all the MemProtMD simulations\n",
    "\n",
    "def get_all_memprotmd_simulations():\n",
    "    return requests.post(MEMPROTMD_ROOT_URI + \"api/simulations/all\").json()\n",
    "\n",
    "get_all_memprotmd_simulations()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a170ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_memprotmd_simulations = pd.DataFrame.from_records(get_all_memprotmd_simulations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed488948",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_memprotmd_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes of PDB that are in the database MemProtMD\n",
    "pdb_codes_memprotmd = all_memprotmd_simulations['accession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have to import the list of PDBs of Central Nervous System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PDB_CNS = '~/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.4.PDB/List_CNS_DruggablePD_Mem_100aa_PDB_Uniprot_correct.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e143a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_CNS = pd.read_csv (path_PDB_CNS,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03e935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PDB_CNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collect all the PDBs of the CNS, separating those that are in the same row also\n",
    "\n",
    "PDBs_CNS_possibleduplicates = []\n",
    "table_PDB = list(PDB_CNS['PDB'])\n",
    "\n",
    "for i in table_PDB: \n",
    "    if ';' in i: \n",
    "        for item in i.split(\";\"):\n",
    "            PDBs_CNS_possibleduplicates.append(item)      \n",
    "    else: \n",
    "        PDBs_CNS_possibleduplicates.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove duplicates PDBs of the CNS\n",
    "\n",
    "PDBs_CNS = []\n",
    "for item in PDBs_CNS_possibleduplicates:\n",
    "    if item not in PDBs_CNS:\n",
    "        PDBs_CNS.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PDBs_CNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbdcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_codes_PDB_CNS = list(PDB_CNS['PDB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the intersection between the MemProtMD codes and the CNS codes of PDB. There may be some duplicates\n",
    "\n",
    "codes_MemProtMD_CNS_possibleduplicates =  []\n",
    "\n",
    "for PDB_MemProtMD in pdb_codes_memprotmd:\n",
    "    for j in list_codes_PDB_CNS:\n",
    "        if PDB_MemProtMD in j:\n",
    "            codes_MemProtMD_CNS_possibleduplicates.append(PDB_MemProtMD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(codes_MemProtMD_CNS_possibleduplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9134591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the duplicates of the previous list\n",
    "# So we have the codes of the MemProtMD of the CNS \n",
    "\n",
    "codes_MemProtMD_CNS = set(codes_MemProtMD_CNS_possibleduplicates)\n",
    "len(codes_MemProtMD_CNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of PDBs of CNS with all filters, no dupli (unique):',len(PDBs_CNS),'\\nNumber of PDBs of CNS with all filters in MemProtMD (unique)',len(codes_MemProtMD_CNS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baaab0b",
   "metadata": {},
   "source": [
    "##### Download the data of MemProt relative to CNS' PDBs already filtered\n",
    "\n",
    "We do it with APIs. From PDB to MemProtMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_all_zip_memprotmd_simulations (pdb_id : str):\n",
    "\n",
    "    # Request the MMB service to retrieve pdb data\n",
    "    request_url = 'http://memprotmd.bioch.ox.ac.uk/data/memprotmd/simulations/'+pdb_id +'_default_dppc/files/run/at.zip'\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(request_url) as response:\n",
    "            parsed_response = requests.get(request_url, allow_redirects=True)\n",
    "            # Write the content to disk\n",
    "            open('/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.5.MemprotMD/Memprot_DruggablePD/'+pdb_id+'_default_dppc-atomistic-simulation_extra.zip', 'wb').write(parsed_response.content)\n",
    "            \n",
    "    # If the accession is not found in the PDB then we can stop here\n",
    "    except urllib.error.HTTPError as error:\n",
    "        if error.code == 404:\n",
    "            return None\n",
    "        else:\n",
    "            raise ValueError('Something went wrong with the PDB request: ' + request_url)\n",
    "    except Exception as error:\n",
    "        print(request_url)\n",
    "        print(error)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for pdb_id in codes_MemProtMD_CNS:\n",
    "    output_file = '/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.5.MemprotMD/Memprot_DruggablePD/'+pdb_id+'_default_dppc-atomistic-simulation.zip'\n",
    "    output_file_extra = '/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.5.MemprotMD/Memprot_DruggablePD/'+pdb_id+'_default_dppc-atomistic-simulation_extra.zip'\n",
    "    if not os.path.exists(output_file) and not os.path.exists(output_file_extra):\n",
    "        print('Requesting ' + pdb_id)\n",
    "        get_all_zip_memprotmd_simulations(pdb_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56586b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(codes_MemProtMD_CNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14079c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PDB_download = \"/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.5.MemprotMD/Memprot_DruggablePD\"\n",
    "path_PDB_download_items = os.listdir(path_PDB_download)\n",
    "\n",
    "for PDB_downloaded in path_PDB_download_items:\n",
    "    \n",
    "    split_string = PDB_downloaded.split('_')\n",
    "    name = split_string[0]\n",
    "    \n",
    "    path_PDB =path_PDB_download+'/'+PDB_downloaded\n",
    "    \n",
    "    \n",
    "    if os.path.getsize(path_PDB) != 0: # If size of the file downloaded is different to 0\n",
    "        \n",
    "        if name not in codes_MemProtMD_CNS and len(name) ==4: # If the name is not in the codes we have collected from CNS and filters\n",
    "\n",
    "            #os.remove(path_PDB) # We remove the file. This is to be sure that the downloaded ones are from the CNS and filters list. \n",
    "            print('Does not make sense the downloaded of this PDB, it is not from our interest list (CNS and filters): ', name)\n",
    "            \n",
    "            \n",
    "    else: # If size of the file downloaded is equal to 0, it was not correctly downloaded and we remove it: \n",
    "        \n",
    "        print('Not correctly downloaded',name)\n",
    "        os.remove(path_PDB) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBs_MemProtMD_correctlydownloaded = [i for i in os.listdir(path_PDB_download) if i != 'ToStudy_NonRepeatedSequences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b24178",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PDBs_MemProtMD_correctlydownloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16332176",
   "metadata": {},
   "source": [
    "#### 2.5.1. Select those that are in MemProtMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PDBs_MemProtMD_correctlydownloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBs_MemProtMD_correctlydownloaded_id = []\n",
    "\n",
    "for pdb_at in PDBs_MemProtMD_correctlydownloaded:\n",
    "    pdb_id = pdb_at[0:4]\n",
    "    PDBs_MemProtMD_correctlydownloaded_id.append(pdb_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41220236",
   "metadata": {},
   "outputs": [],
   "source": [
    "UniprotMD_list = []\n",
    "PDBMD_list = []\n",
    "ChainsMD_list = []\n",
    "InfoChainsMD_list = []\n",
    "MethodMD_list = []\n",
    "ResolutionMD_list = []\n",
    "gene_nameMD_list = []\n",
    "\n",
    "for idx in range(len(PDBs_MemProtMD_correctlydownloaded_id)):\n",
    "    if PDBs_MemProtMD_correctlydownloaded_id[idx] in list(table_proteins_PDB_CNS_membrane_l100['PDB']): \n",
    "        \n",
    "        UniprotMD_indi = list(table_proteins_PDB_CNS_membrane_l100[table_proteins_PDB_CNS_membrane_l100['PDB'] == PDBs_MemProtMD_correctlydownloaded_id[idx]][table_proteins_PDB_CNS_membrane_l100.columns[0]])\n",
    "        PDBMD_indi = list(table_proteins_PDB_CNS_membrane_l100[table_proteins_PDB_CNS_membrane_l100['PDB'] == PDBs_MemProtMD_correctlydownloaded_id[idx]][table_proteins_PDB_CNS_membrane_l100.columns[1]])\n",
    "        ChainsMD_indi=list(table_proteins_PDB_CNS_membrane_l100[table_proteins_PDB_CNS_membrane_l100['PDB'] == PDBs_MemProtMD_correctlydownloaded_id[idx]][table_proteins_PDB_CNS_membrane_l100.columns[2]])\n",
    "        InfoChainsMD_indi = list(table_proteins_PDB_CNS_membrane_l100[table_proteins_PDB_CNS_membrane_l100['PDB'] == PDBs_MemProtMD_correctlydownloaded_id[idx]][table_proteins_PDB_CNS_membrane_l100.columns[3]])\n",
    "        MethodMD_indi = list(table_proteins_PDB_CNS_membrane_l100[table_proteins_PDB_CNS_membrane_l100['PDB'] == PDBs_MemProtMD_correctlydownloaded_id[idx]][table_proteins_PDB_CNS_membrane_l100.columns[4]])\n",
    "        ResolutionMD_indi = list(table_proteins_PDB_CNS_membrane_l100[table_proteins_PDB_CNS_membrane_l100['PDB'] == PDBs_MemProtMD_correctlydownloaded_id[idx]][table_proteins_PDB_CNS_membrane_l100.columns[5]])\n",
    "        gene_nameMD_indi = list(table_proteins_PDB_CNS_membrane_l100[table_proteins_PDB_CNS_membrane_l100['PDB'] == PDBs_MemProtMD_correctlydownloaded_id[idx]][table_proteins_PDB_CNS_membrane_l100.columns[6]])\n",
    "        \n",
    "        \n",
    "        UniprotMD_list.append(UniprotMD_indi)\n",
    "        PDBMD_list.append(PDBMD_indi)\n",
    "        ChainsMD_list.append(ChainsMD_indi)\n",
    "        InfoChainsMD_list.append(InfoChainsMD_indi)\n",
    "        MethodMD_list.append(MethodMD_indi)\n",
    "        ResolutionMD_list.append(ResolutionMD_indi)\n",
    "        gene_nameMD_list.append(gene_nameMD_indi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910db66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_UniprotMD_list = [item for sublist in UniprotMD_list for item in sublist]\n",
    "ready_PDBMD_list = [item for sublist in PDBMD_list for item in sublist]\n",
    "ready_ChainsMD_list = [item for sublist in ChainsMD_list for item in sublist]\n",
    "ready_InfoChainsMD_list = [item for sublist in InfoChainsMD_list for item in sublist]\n",
    "ready_MethodMD_list = [item for sublist in MethodMD_list for item in sublist]\n",
    "ready_ResolutionMD_list = [item for sublist in ResolutionMD_list for item in sublist]\n",
    "ready_gene_nameMD_list = [item for sublist in gene_nameMD_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_MemProt= {'Uniprot':ready_UniprotMD_list,'PDB':ready_PDBMD_list,'Chains':ready_ChainsMD_list,'Info Chains: chain, seq, fragments':ready_InfoChainsMD_list,'Experimental method':ready_MethodMD_list,'Experimental Resolution':ready_ResolutionMD_list,'gene_name':ready_gene_nameMD_list}\n",
    "table_proteins_PDB_CNS_membrane_l100_MemProtMD = pd.DataFrame.from_dict(data_MemProt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f80515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100_MemProtMD.sort_values(by = ['Uniprot','PDB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852496fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_unique = table_proteins_PDB_CNS_membrane_l100_MemProtMD['Uniprot'].unique()\n",
    "\n",
    "uniprots_length = []\n",
    "length_list = []\n",
    "\n",
    "for i in Uniprot_unique: \n",
    "    \n",
    "    length = len(table_proteins_PDB_CNS_membrane_l100_MemProtMD[table_proteins_PDB_CNS_membrane_l100_MemProtMD['Uniprot'] == i])\n",
    "    uniprots_length.append(i)\n",
    "    length_list.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be60dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_leng_idx = length_list.index(max(length_list))\n",
    "print(max(length_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dca178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniprots_length[max_leng_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_proteins_PDB_CNS_membrane_l100_MemProtMD.to_csv('1_DruggablePD_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100_MemProtMD.to_csv('1_DruggablePD_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100_correct_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0651f91",
   "metadata": {},
   "source": [
    "#### 2.5.2. Select those not in MemProtMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_id_Memprot_copy = table_proteins_PDB_CNS_membrane_l100_MemProtMD['PDB']\n",
    "Uniprot_id_Memprot_copy = table_proteins_PDB_CNS_membrane_l100_MemProtMD['Uniprot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a51598",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100_notMemProt = table_proteins_PDB_CNS_membrane_l100\n",
    "\n",
    "for PDB_id_Memprot,Uniprot_id_Memprot in zip(PDB_id_Memprot_copy,Uniprot_id_Memprot_copy): \n",
    "    table_proteins_PDB_CNS_membrane_l100_notMemProt.drop(table_proteins_PDB_CNS_membrane_l100_notMemProt[(table_proteins_PDB_CNS_membrane_l100_notMemProt['PDB'] == PDB_id_Memprot) & (table_proteins_PDB_CNS_membrane_l100_notMemProt['Uniprot'] == Uniprot_id_Memprot)].index,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaacad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100_notMemProt.sort_values(by = ['Uniprot','PDB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_proteins_PDB_CNS_membrane_l100_notMemProt.to_csv('2_DruggablePD_NOT_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100_notMemProt.to_csv('2_DruggablePD_NOT_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100_correct_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45b585",
   "metadata": {},
   "source": [
    "#### 2.5.3. Only PDB table (not Uniprot) and non-repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7715529",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = pd.read_csv('1_DruggablePD_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100_correct_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eda2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1.drop('Uniprot', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1_noduplisPDB = list1.drop_duplicates(subset=['PDB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb20b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1_noduplisPDB.to_csv('1_DruggablePD_nodupliPDB_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100_correct_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list1_noduplisPDB.to_csv('1_DruggablePD_nodupliPDB_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list1_noduplisPDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca84afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = pd.read_csv('2_DruggablePD_NOT_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100_correct_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2.drop('Uniprot', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de57db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2_noduplisPDB = list2.drop_duplicates(subset=['PDB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd2d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list2_noduplisPDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2_noduplisPDB.to_csv('2_DruggablePDB_nodupliPDB_NOT_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100_correct_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list2_noduplisPDB.to_csv('2_DruggablePDB_nodupliPDB_NOT_IN_MEMPROTMD_table_proteins_PDB_CNS_membrane_l100.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d790296",
   "metadata": {},
   "source": [
    "### 3. PDBs not equal-selection\n",
    "\n",
    "##### From PD and Memprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a513736",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100_MemProtMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprots_memprot = table_proteins_PDB_CNS_membrane_l100_MemProtMD['Uniprot'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f28e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBs_memprot_for_uniqueUniprot =[]\n",
    "\n",
    "for i in uniprots_memprot: \n",
    "    PDBs_ = list(table_proteins_PDB_CNS_membrane_l100_MemProtMD[table_proteins_PDB_CNS_membrane_l100_MemProtMD['Uniprot'] ==i]['PDB'])\n",
    "    PDBs_memprot_for_uniqueUniprot.append(PDBs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBs_memprot_for_uniqueUniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c905923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Given a pdb id return the explicit sequence\n",
    "def get_pdb_seq (pdb_id : str) -> list:\n",
    "    # Request the MMB service to retrieve pdb data\n",
    "    request_url = 'https://mmb.irbbarcelona.org/api/pdb/' + pdb_id + '/entry'\n",
    "    try:\n",
    "        with urllib.request.urlopen(request_url) as response:\n",
    "            parsed_response = json.loads(response.read().decode(\"utf-8\"))\n",
    "    # If the accession is not found in the PDB then we can stop here\n",
    "    except urllib.error.HTTPError as error:\n",
    "        if error.code == 404:\n",
    "            print('NOT FOUND')\n",
    "            return {pdb_id:None}\n",
    "        else:\n",
    "            raise ValueError('Something went wrong with the PDB request: ' + request_url)\n",
    "    \n",
    "    # If there are no chains we are done\n",
    "    if parsed_response['chainIds'] == None:\n",
    "        print('NO CHAINS ' + pdb_id)\n",
    "        return {pdb_id:None}\n",
    "\n",
    "    seqs = [] # Conjunto de secuencia de PDB para cada cadena. [1 --> seq cadena A, 2--> seq cadena B...]\n",
    "    for chain in parsed_response['chains']:\n",
    "        if chain['PDBSequence'] != None: \n",
    "            #chain_id = chain['_id'][-1]\n",
    "            seq = chain['PDBSequence']['sequence'] # Cogemos la secuencia del PDB de cada cadena\n",
    "            seqs.append(seq)\n",
    "\n",
    "    return {pdb_id:seqs} # Devuelve lista de secuencias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31709d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a special iteration system\n",
    "# Return one value of the array and a new array with all other values for each value\n",
    "def otherwise (values : list) -> Generator[tuple, None, None]: # Pondremos la lista (listo) como argumento\n",
    "    for v, value in enumerate(values): # de cada listi dentro de esta lista, seleccionamos su índice dentro de la lista y tal cual la listi. \n",
    "        others = values[v+1:] # Seleccionamos todas aquellas listis dentro de la lista diferentes a la iterada (diferentes a la del PDB). \n",
    "        yield value, others # Devolvemos la listi iterada y el resto de listis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff939cb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdb_to_study = []\n",
    "pdbs_disc = []\n",
    "\n",
    "for sample in PDBs_memprot_for_uniqueUniprot: \n",
    "    \n",
    "    #print('SAMPLE: ',sample)\n",
    "    #print([ get_pdb_seq(s) for s in sample ])\n",
    "    \n",
    "    seqs = [ get_pdb_seq(s).get(s) for s in sample ] # Para cada PDB, hacemos una lista de listas de cada cadena. Esto para cada UniProt\n",
    "    #print('SECUENCIA ????',seqs)\n",
    "    seqs = [ s for s in seqs if s ] # Descartamos aquellas que son None (con falsy). \n",
    "    #print('SECUENCIA',seqs)\n",
    "\n",
    "\n",
    "    # seqs es una lista (listo) de listas (listi) donde dentro de esta listi cada elemento es una cadena de ese PDB y cada\n",
    "    # elemento de la lista (listo) es un PDB distinto. \n",
    "\n",
    "    \n",
    "    discarded = [] # Lista de secuencias descartadas\n",
    "\n",
    "    for i, (seq_set, other_seq_sets) in enumerate(otherwise(seqs)): # Aplicamos la funcion otherwise a todos los eleementos\n",
    "                                                                    # de la lista seqs. \n",
    "                                                                    # Seq_set será una lista de listas de todas las cadenas de ese PDB\n",
    "                                                                    # o si tiene una cadena será solo esa cadena del PDB\n",
    "                                                                    # Other_seq_sets será una lista de listas de todas las otras cadenas del resto de PDBs\n",
    "                                                                    # o si solo tiene 1 cadena ese PDB, una lista de esa cadena en los distintos PDBs. \n",
    "\n",
    "        if i in discarded: # Si el índice de esa cadena ya lo hemos descartado antes, pues nada, continua. \n",
    "            continue\n",
    "\n",
    "        #1r filtro de longitud\n",
    "        for j, other_seq_set in enumerate(other_seq_sets): # Para cada 'other' secuencia\n",
    "            # Compare sequences one by one\n",
    "            if len(seq_set) != len(other_seq_set): # Si la longitud de la cadena/s seleccionada es diferent a la del resto(s) de cadena, entonces ya queda\n",
    "                                                    # sabemos que serán diferentes entre ellas, entonces coninúamos. \n",
    "                continue\n",
    "            mismatch = False # Atribuímos el valor False a la variable mismatch\n",
    "\n",
    "\n",
    "            for seq in seq_set: # Para cada secuencia (cada cadena) de ese PDB \n",
    "                if seq not in other_seq_set: # si la secuencia no se encuentra en la lista de las otras secuencias\n",
    "                    mismatch = True # Le damos el valor de True a la variable mismatch\n",
    "                    break # y dejamos el bucle porque si no se encuentra eso es que es diferente y por lo tanto nos interesa. \n",
    "                          # nos interesan aquellos PDBs que tienen alguna de sus cadenas diferentes al resto. \n",
    "            if mismatch: # si el mismatch es True\n",
    "                continue # se sigue\n",
    "            # Current seqs are repeated\n",
    "            discarded.append(i+j+1) # en el caso de que la len sea igual, y la secuencia se encuentre en la lista de las otras\n",
    "                                    # añadimos el índice del PDB \n",
    "\n",
    "\n",
    "    unique_seqs = [ s for i, s in enumerate(seqs) if i not in discarded ] # de la lista de secuencias, hacemos \n",
    "                                                                            # una lista de aquellas que no han sido \n",
    "                                                                            # descartadas\n",
    "    discard_seq = [s for i, s in enumerate(seqs) if i in discarded ]\n",
    "    \n",
    "    dic =[ get_pdb_seq(s) for s in sample ] # definimos el diccionario de antes. Es una lista de muchos diccionarios\n",
    "\n",
    "    result = {} # Hacemos que la lista de diccionarios sea 1D, es decir, una única lista de 1 diccionario\n",
    "    for d in dic:\n",
    "        result.update(d)\n",
    "     \n",
    "    \n",
    "    pdbs_with_same_seq= [] \n",
    "\n",
    "    for i in unique_seqs: #Para cada secuencia única de PDB que hemos encontrado\n",
    "        keys = get_keys_from_value(result,i) # De esta secuencia, nos devuelve el PDB (la key del diccionario). \n",
    "                                            # Tenemos secuencias que son únicas pertenecientes a un solo PDB\n",
    "                                            # Pero también tenemos aquella secuencia que se repite en varios PDBs\n",
    "                                            # Si varios PDBs la tienen, solo la queremos estudiar 1 vez, \n",
    "                                            # por eso haremos lo siguiente: \n",
    "        pdbs_with_same_seq.append(keys)\n",
    "    \n",
    "\n",
    "    for pdb in pdbs_with_same_seq:\n",
    "        pdb_stu = pdb[0] # De la lista de listas de PDBs, cogemos el primero. Es indiferent cuál PDB cogemos porque \n",
    "                        # si se repite la secuencia en varios, será el PDB pero con distinto nombre. \n",
    "        pdb_to_study.append(pdb_stu)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    for i in discard_seq:\n",
    "        keys = get_keys_from_value(result,i)\n",
    "        pdbs_disc.append(keys)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84a21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdbs_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_to_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdb_to_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d95d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_to_study_unique = list(set(pdb_to_study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdb_to_study_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f82c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(pdb_to_study_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table_proteins_PDB_CNS_membrane_l100_MemProtMD['Uniprot'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263cbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(table_proteins_PDB_CNS_membrane_l100_MemProtMD['Uniprot'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48324d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_proteins_PDB_CNS_membrane_l100_MemProtMD['PDB'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_to_study_unique.sort()\n",
    "pdb_to_study_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PDB_download = \"/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.5.MemprotMD/Memprot_DruggablePD\"\n",
    "path_PDB_down_tocopy = '/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.5.MemprotMD/Memprot_DruggablePD/ToStudy_NonRepeatedSequences'\n",
    "\n",
    "path_PDB_download_items = os.listdir(path_PDB_download)\n",
    "\n",
    "\n",
    "for PDB_downloaded in path_PDB_download_items:\n",
    "    \n",
    "    split_string = PDB_downloaded.split('_')\n",
    "    name = split_string[0]\n",
    "    \n",
    "    if name in pdb_to_study_unique:\n",
    "        path_PDB_copy =path_PDB_down_tocopy+'/'+PDB_downloaded\n",
    "        path_PDB = path_PDB_download + '/' +PDB_downloaded\n",
    "        if not os.path.exists(path_PDB_copy):\n",
    "            print(PDB_downloaded)\n",
    "            shutil.copyfile(path_PDB, path_PDB_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3691179",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = []\n",
    "import os\n",
    "for file in os.listdir(path_PDB_down_tocopy): \n",
    "    file_splitted = file.split('_')\n",
    "    if len(file_splitted[0]) == 4: \n",
    "        zips.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24839877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PDB_down_tocopy_unzipped = path_PDB_down_tocopy+'/'+'unzipped'\n",
    "pdbs_ids_unzipped = []\n",
    "\n",
    "for file_unzipped in os.listdir(path_PDB_down_tocopy_unzipped): \n",
    "    pdb_id_unzip = file_unzipped.split('_') \n",
    "    pdbs_ids_unzipped.append(pdb_id_unzip[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78695d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdbs_ids_unzipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52047928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "for file in os.listdir(path_PDB_down_tocopy):\n",
    "    \n",
    "    \n",
    "    pdb_file_zip = file.split('_')\n",
    "    pdb_id_zipped = pdb_file_zip[0]\n",
    "    \n",
    "    if pdb_id_zipped not in pdbs_ids_unzipped and len(pdb_id_zipped) == 4:\n",
    "        print(file)\n",
    "        with zipfile.ZipFile('/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.5.MemprotMD/Memprot_DruggablePD/ToStudy_NonRepeatedSequences/'+file, 'r') as zip_ref:\n",
    "            zip_ref.extractall('/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_List_proteins/AllJupyters/2.Filters/2.5.MemprotMD/Memprot_DruggablePD/ToStudy_NonRepeatedSequences/unzipped/'+pdb_id_zipped+'_default_dppc-atomistic-simulation_extra')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
