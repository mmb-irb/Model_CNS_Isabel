{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362bd610",
   "metadata": {},
   "source": [
    "# Analysis. \n",
    "## Insert needed files for each PDB for running the test analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada39f1",
   "metadata": {},
   "source": [
    "The needed file is the inputs.json. We have previously created one and then, we are going to edit this each time for each PDB and export it to the PDB folder. \n",
    "\n",
    "This file is necessary to run this command which will run all the test analysis: \n",
    "\n",
    "mwf -top md.tpr -traj md.xtc -char md.tpr -pr 4 -filt -i topology --trust cohbonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc5dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os \n",
    "import json\n",
    "import urllib.request\n",
    "from typing import List\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e72fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the inputs.json file in the PDBs that have finished its dynamics. \n",
    "\n",
    "\n",
    "# Define an empty list\n",
    "finished_run_pdbs = []\n",
    "\n",
    "# Open the file and read the content in a list\n",
    "\n",
    "with open('/home/imartinv/Escritorio/TFG/1.LIST_PROTEINS/Isa_dinÃ¡micas_preparacion/PDBS_finished_difference.txt', 'r') as finished_file:\n",
    "    for line in finished_file:\n",
    "        # Remove linebreak which is the last character of the string\n",
    "        curr_place = line[:-1]\n",
    "        # Add item to the list\n",
    "        finished_run_pdbs.append(curr_place)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9245a33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4cof', '5zkb', '6a94', '5zk3', '5zk8', '6cm4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished_run_pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d33b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to obtain the description of the PDB, which will be needed for the inputs.json file \n",
    "# that is necesary for running the test analysis. \n",
    "\n",
    "def pdb_descr (pdb_id : str) -> List[str]:\n",
    "    # Request the MMB service to retrieve pdb data\n",
    "    request_url = 'https://mmb.irbbarcelona.org/api/pdb/' + pdb_id + '/entry'\n",
    "    try:\n",
    "        with urllib.request.urlopen(request_url) as response:\n",
    "            parsed_response = json.loads(response.read().decode(\"utf-8\"))\n",
    "    # If the accession is not found in the PDB then we can stop here\n",
    "    except urllib.error.HTTPError as error:\n",
    "        if error.code == 404:\n",
    "            return None\n",
    "        else:\n",
    "            raise ValueError('Something went wrong with the PDB request: ' + request_url)\n",
    "    \n",
    "    # Get the uniprot accessions\n",
    "    \n",
    "    compound = parsed_response['compound']\n",
    "    \n",
    "    return compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b35c480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4cof\n",
      "5zkb\n",
      "6a94\n",
      "5zk3\n",
      "5zk8\n",
      "6cm4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for pdb_id in finished_run_pdbs: \n",
    "    # Create folder for doing the tests because this test will give us a lot of files.\n",
    "    print(pdb_id)\n",
    "\n",
    "    pdb_path = '/home/imartinv/Escritorio/ventana_a_starlife/CNS_PD_Memprot_dynamics/'+pdb_id+'_default_dppc-atomistic-simulation' # Path of the PDB folder\n",
    "\n",
    "    directory_path_analysis = pdb_path+'/analysis_checkdynamics' # Directory we want to create. \n",
    "\n",
    "    if not os.path.exists(directory_path_analysis): # We create the directory if it was not previously created, just in case. \n",
    "        os.mkdir(directory_path_analysis)\n",
    "        # If it was previously created, then it means that we have already created the inputs.json \n",
    "        \n",
    "        # Read and modify previous inputs.json\n",
    "        \n",
    "        inputs_filename = '/home/imartinv/Escritorio/test/inputs.json'# Directory of where the inputs.json is (the original one)\n",
    "\n",
    "        with open(inputs_filename, 'r') as file:\n",
    "            inputs = json.load(file)\n",
    "            \n",
    "        # We edit parameters. \n",
    "        inputs['name'] = 'Molecular dynamics '+ pdb_descr(pdb_id)\n",
    "        inputs['description'] = 'Simulation of '+ pdb_descr(pdb_id)\n",
    "        inputs['links'][0]['url'] = 'http://memprotmd.bioch.ox.ac.uk/_ref/PDB/'+pdb_id+'/_sim/'+pdb_id+'_default_dppc/'\n",
    "        inputs['pdbIds'] = [pdb_id]\n",
    "        \n",
    "        \n",
    "\n",
    "        # To know which force field it is using\n",
    "        with open('/home/imartinv/Escritorio/ventana_a_starlife/CNS_PD_Memprot_dynamics/'+pdb_id+'_default_dppc-atomistic-simulation'+'/topol.top') as topol_top:\n",
    "\n",
    "            topol_top_lines_f = topol_top.readlines() # We read line by line the error3.log file\n",
    "\n",
    "        for line_top in topol_top_lines_f:\n",
    "\n",
    "            if 'gromos53a6'in line_top:\n",
    "                inputs['ff']  = '53A6 GROMOS'\n",
    "\n",
    "            elif 'charmm36' in line_top:\n",
    "                inputs['ff'] = 'CHARMM36'\n",
    "\n",
    "            elif 'gromos53a6' in line_top and 'charmm36' in line_top:\n",
    "                inputs['ff'] = ['53A6 GROMOS', 'CHARMM36']\n",
    "\n",
    "\n",
    "        # Export changes\n",
    "        with open(inputs_filename, 'w') as file:\n",
    "            json.dump(inputs, file, indent=4)\n",
    "            \n",
    "        \n",
    "        file_json = directory_path_analysis+'/inputs.json'\n",
    "        shutil.copyfile(inputs_filename,file_json)\n",
    "        \n",
    "        \n",
    "        ## Copy other files needed for the analysis: \n",
    "        file_needed_1 = '/home/imartinv/Escritorio/ventana_a_starlife/CNS_PD_Memprot_dynamics/'+pdb_id+'_default_dppc-atomistic-simulation/100ns/md.xtc'\n",
    "\n",
    "        file_needed_2 = '/home/imartinv/Escritorio/ventana_a_starlife/CNS_PD_Memprot_dynamics/'+pdb_id+'_default_dppc-atomistic-simulation/100ns/md.tpr'\n",
    "\n",
    "        shutil.copyfile(file_needed_1,directory_path_analysis+'/md.xtc')\n",
    "        shutil.copyfile(file_needed_2,directory_path_analysis+'/md.tpr')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
